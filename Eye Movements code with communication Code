# eye_sender_pi.py
# Runs on Raspberry Pi - performs eye tracking and sends commands

from __future__ import annotations
import sys
import time
import cv2
import mediapipe as mp
import numpy as np
from collections import deque
import platform
import subprocess
import re
import os
import socket 

# ----------- USER SETTINGS -------------
# ** Network Settings **
LAPTOP_IP = '192.178.6.178' 
PORT = 9999                  


CAM_INDEX = 0
CAM_WIDTH, CAM_HEIGHT = 640, 480
FPS_LIMIT = 30
SMOOTH = 3
STABLE_FRAMES = 2
CENTER_WIDTH_PCT = 15 
COOLDOWN_SECONDS = 0.5 
USE_ARROW_KEYS = False 

# Blink detection
BLINK_THRESHOLD = 0.19
BLINK_COOLDOWN_S = 0.6

# Long blink for pause/resume
LONG_BLINK_THRESHOLD = 0.19
LONG_BLINK_DURATION = 1.0
PAUSE_RESUME_COOLDOWN = 2.0

# Debug
DEBUG_WINDOW = True 
try:
    import mediapipe as mp
except ImportError:
    print("Error: MediaPipe not found. Please install:")
    print(" pip install mediapipe")
    sys.exit(1)
if platform.system() == 'Linux':
    if 'DISPLAY' not in os.environ:
        print("‚ö†Ô∏è Warning: DISPLAY environment variable not set, defaulting to :0 (Needed for debug window)")
        os.environ['DISPLAY'] = ':0'
  
PI_SCREEN_W, PI_SCREEN_H = 0, 0
try:
    # Attempt to get Pi's screen size for context, but not critical
    # Using 'xdpyinfo' or 'xrandr' might work on Raspbian with Desktop
    if platform.system() == 'Linux' and os.system("which xrandr > /dev/null 2>&1") == 0:
         output = subprocess.check_output('xrandr | grep \* | cut -d" " -f4', shell=True).decode()
         match = re.match(r'(\d+)x(\d+)', output)
         if match:
             PI_SCREEN_W, PI_SCREEN_H = int(match.group(1)), int(match.group(2))
             print(f" Pi Display Info (for context): {PI_SCREEN_W}x{PI_SCREEN_H} pixels")
         else:
             print(" Could not parse Pi screen size from xrandr.")
    else:
        print(" Cannot determine Pi screen size (Non-Linux or xrandr not found).")
except Exception as e:
    print(f" Note: Could not detect Pi screen size: {e}")
    PI_SCREEN_W, PI_SCREEN_H = CAM_WIDTH, CAM_HEIGHT # Fallback for debug text

try:
    cam = None
    if platform.system() == 'Windows': # Less likely on Pi, but keep for generality
        cam = cv2.VideoCapture(CAM_INDEX, cv2.CAP_DSHOW)
    else: # Linux (Raspberry Pi)
        cam = cv2.VideoCapture(CAM_INDEX)
        if not cam.isOpened():
            cam.release()
            print("Trying V4L2 backend for camera...")
            cam = cv2.VideoCapture(CAM_INDEX, cv2.CAP_V4L2)

    if cam.isOpened():
        cam.set(cv2.CAP_PROP_FRAME_WIDTH, CAM_WIDTH)
        cam.set(cv2.CAP_PROP_FRAME_HEIGHT, CAM_HEIGHT)
        cam.set(cv2.CAP_PROP_FPS, FPS_LIMIT) # Try setting FPS
        ret, frame = cam.read()
        if not ret or frame is None or frame.size == 0:
             raise Exception("Camera returned empty frame")
        print(f" Camera {CAM_INDEX} opened successfully ({CAM_WIDTH}x{CAM_HEIGHT})")
    else:
        raise Exception(f"Could not open camera with index {CAM_INDEX}")
except Exception as e:
    print(f" FATAL: Camera initialization error: {e}")
    print(" Please check camera connection, permissions (e.g., `sudo usermod -a -G video $USER`), and index.")
    sys.exit(1)

mp_face = mp.solutions.face_mesh
face_mesh = mp_face.FaceMesh(max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5)
L_EYE, R_EYE = [33, 133], [362, 263]
L_IRIS, R_IRIS = 468, 473
L_TOP, L_BOTTOM = 159, 145
R_TOP, R_BOTTOM = 386, 374
np_norm = np.linalg.norm

def to_px(lm, idx):
    try:
        p = lm[idx]
        return np.array([int(p.x * CAM_WIDTH), int(p.y * CAM_HEIGHT)])
    except IndexError:
        # print(f"Warning: Landmark index {idx} out of bounds.")
        return np.array([0, 0]) # Return a default point

def iris_ratio(lm):
    """Calculate normalized iris position within eye bounds"""
    li, ri = to_px(lm, L_IRIS), to_px(lm, R_IRIS)
    lL, lR = to_px(lm, L_EYE[0]), to_px(lm, L_EYE[1])
    rL, rR = to_px(lm, R_EYE[0]), to_px(lm, R_EYE[1])

    l_eye_width = lR[0] - lL[0]
    r_eye_width = rR[0] - rL[0]
    rx_l = (li[0] - lL[0]) / (l_eye_width + 1e-6) if l_eye_width != 0 else 0.5
    rx_r = (ri[0] - rL[0]) / (r_eye_width + 1e-6) if r_eye_width != 0 else 0.5
    rx = (rx_l + rx_r) / 2

    lT, lB = to_px(lm, L_TOP), to_px(lm, L_BOTTOM)
    rT, rB = to_px(lm, R_TOP), to_px(lm, R_BOTTOM)
    l_eye_height = lB[1] - lT[1]
    r_eye_height = rB[1] - rT[1]
    ry_l = (li[1] - lT[1]) / (l_eye_height + 1e-6) if l_eye_height != 0 else 0.5
    ry_r = (ri[1] - rT[1]) / (r_eye_height + 1e-6) if r_eye_height != 0 else 0.5
    ry = (ry_l + ry_r) / 2

    return np.array([np.clip(rx, 0, 1), np.clip(ry, 0, 1)]) # Clip values to 0-1

def ear(lm):
    """Calculate eye aspect ratio for blink detection"""
    lT, lB = to_px(lm, L_TOP), to_px(lm, L_BOTTOM)
    rT, rB = to_px(lm, R_TOP), to_px(lm, R_BOTTOM)
    lL, lR = to_px(lm, L_EYE[0]), to_px(lm, L_EYE[1])
    rL, rR = to_px(lm, R_EYE[0]), to_px(lm, R_EYE[1])

    def _ear(T, B, L, R):
        eye_width = np_norm(L - R)
        return np_norm(T - B) / (eye_width + 1e-6) if eye_width != 0 else 0

    try:
        ear_l = _ear(lT, lB, lL, lR)
        ear_r = _ear(rT, rB, rL, rR)
        return (ear_l + ear_r) / 2
    except Exception as e:
        # print(f"Warning: Error calculating EAR: {e}")
        return 0.5 # Return a neutral value on error

# -------- Socket Setup -------------
client_socket = None
def setup_socket():
    global client_socket
    if client_socket:
        try:
            client_socket.close()
        except: pass
    client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    client_socket.settimeout(2.0) # Timeout for connection attempt
    try:
        print(f"Attempting to connect to {LAPTOP_IP}:{PORT}...")
        client_socket.connect((LAPTOP_IP, PORT))
        client_socket.settimeout(None) # Remove timeout after connection
        print("‚úÖ Connected to Laptop Receiver.")
        return True
    except (socket.error, socket.timeout) as e:
        print(f"‚ùå Connection failed: {e}. Check Laptop IP and if receiver script is running.")
        client_socket = None
        return False

def send_command(command):
    global client_socket
    if not client_socket:
        print("No connection. Attempting to reconnect...")
        if not setup_socket():
            print("Reconnect failed. Command not sent.")
            return False # Indicate send failure

    try:
        # print(f"Sending command: {command}") # Uncomment for verbose sending log
        client_socket.sendall(command.encode('utf-8'))
        return True # Indicate send success
    except socket.error as e:
        print(f"‚ùå Send failed: {e}. Connection lost.")
        client_socket = None # Reset socket state
        # Optional: Attempt immediate reconnect here, or wait for next command
        # print("Attempting immediate reconnect...")
        # setup_socket()
        return False # Indicate send failure


# -------- Main Loop Setup ------------
# (Keep original setup for tracking logic)
half_center = CENTER_WIDTH_PCT / 200.0
left_threshold = 0.5 - half_center
right_threshold = 0.5 + half_center

print("\n--- Eye Tracking Sender (Raspberry Pi) ---")
print(f"Target Laptop IP: {LAPTOP_IP}:{PORT}")
print(f"Center dead zone: {CENTER_WIDTH_PCT}% (x: {left_threshold:.2f} to {right_threshold:.2f})")
print(" Look Left -> Send MOVE_LEFT")
print(" Look Right -> Send MOVE_RIGHT")
print(" Blink -> Send CLICK")
print(" Long Blink -> Send TOGGLE_PAUSE")
print(f" Debug Window: {'Enabled' if DEBUG_WINDOW else 'Disabled'}")
print("Press Ctrl+C in terminal to exit.")

sm_x, sm_y = deque(maxlen=SMOOTH), deque(maxlen=SMOOTH)
last_emit_time = 0.0
stable_count = 0
prev_label = 'centre'
blink_cooldown_end = 0.0
last_pause_toggle_time = 0.0
eye_close_start_time = 0.0
is_receiver_paused = False # Track receiver pause state locally for debug display
last_connection_attempt = 0

# -------- Initial Connection Attempt --------
setup_socket()

# -------- Main Loop ------------------
prev_frame_time = time.time()
try:
    while True:
        now = time.time()

        # Handle reconnection attempts periodically if disconnected
        if not client_socket and now - last_connection_attempt > 5.0: # Retry every 5 seconds
             print("Retrying connection...")
             setup_socket()
             last_connection_attempt = now

        # --- Frame Capture and Processing ---
        try:
            ok, frame = cam.read()
            if not ok or frame is None or frame.size == 0:
                # print("Warning: Camera frame issue.") # Reduce console spam
                time.sleep(0.1)
                continue

            # Flip frame if needed (some cameras are mirrored)
            # frame = cv2.flip(frame, 1)

            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            rgb_frame.flags.writeable = False # Optimize
            results = face_mesh.process(rgb_frame)
            rgb_frame.flags.writeable = True # Re-enable if drawing later

        except Exception as e:
            print(f"Error processing frame: {e}")
            time.sleep(0.1)
            continue

        # --- Landmark Extraction and Logic ---
        label = 'centre'
        median_pos = np.array([0.5, 0.5])
        current_ear = 0.5 # Default neutral EAR

        if results.multi_face_landmarks:
            landmarks = results.multi_face_landmarks[0].landmark # Assuming one face

            # Check if landmark list is populated sufficiently before accessing indices
            max_needed_idx = max(L_IRIS, R_IRIS, L_TOP, L_BOTTOM, R_TOP, R_BOTTOM, L_EYE[0], L_EYE[1], R_EYE[0], R_EYE[1])
            if len(landmarks) > max_needed_idx:
                # Get eye position
                vec = iris_ratio(landmarks)
                sm_x.append(vec[0])
                sm_y.append(vec[1])
                median_pos = np.array([np.median(sm_x), np.median(sm_y)])

                # Determine region
                if median_pos[0] < left_threshold:
                    label = 'right' # Looking left sends RIGHT command to move cursor right
                elif median_pos[0] > right_threshold:
                    label = 'left'  # Looking right sends LEFT command to move cursor left
                else:
                    label = 'centre'

                # Eye aspect ratio for blinks
                current_ear = ear(landmarks)

                if current_ear < BLINK_THRESHOLD and now > blink_cooldown_end:
                    print(f"üëÅÔ∏è  Blink detected (EAR: {current_ear:.3f}) -> Sending CLICK")
                    if send_command("CLICK"): # Check if send was successful
                        blink_cooldown_end = now + BLINK_COOLDOWN_S
                        last_emit_time = now # Reset emit timer on click too
                        stable_count = 0     # Reset stability on click
                    else:
                        print(" Failed to send CLICK command.")


                # Long Blink (Pause/Resume)
                if current_ear < LONG_BLINK_THRESHOLD:
                    if eye_close_start_time == 0:
                         eye_close_start_time = now # Start timer
                    elif now - eye_close_start_time >= LONG_BLINK_DURATION:
                         # Check cooldown for pause/resume toggle itself
                         if now > last_pause_toggle_time + PAUSE_RESUME_COOLDOWN:
                             print(f"üëÅÔ∏èüëÅÔ∏è Long Blink ({now - eye_close_start_time:.2f}s) -> Sending TOGGLE_PAUSE")
                             if send_command("TOGGLE_PAUSE"):
                                 is_receiver_paused = not is_receiver_paused # Toggle local state for display
                                 last_pause_toggle_time = now
                                 eye_close_start_time = 0 # Reset timer after successful toggle
                                 # Optional: add a small delay after pause toggle?
                             else:
                                 print(" Failed to send TOGGLE_PAUSE command.")
                                 # Don't change local state or reset timer if send failed
                         #else: # Cooldown active for toggle
                             #pass # Don't send command yet
                elif current_ear >= LONG_BLINK_THRESHOLD:
                    eye_close_start_time = 0 # Reset timer if eyes open

                # Stability filter for movement
                if label == prev_label:
                    stable_count += 1
                else:
                    stable_count = 1
                    prev_label = label

                # Emit Movement Command
                # No check for 'is_receiver_paused' here, receiver handles pause state
                if label != 'centre' and stable_count >= STABLE_FRAMES and now - last_emit_time > COOLDOWN_SECONDS:
                    command_to_send = f"MOVE_{label.upper()}"
                    print(f"‚û°Ô∏è  {label.upper()} (Stable: {stable_count}) -> Sending {command_to_send}")
                    if send_command(command_to_send):
                        last_emit_time = now
                        # Don't reset stable_count on successful send, allow continuous movement
                        # stable_count = 0 # <<< Keep commented
                    else:
                        print(f" Failed to send {command_to_send} command.")
                        # Consider resetting stable_count if send fails? Or just wait for reconnect?
                        stable_count = 0 # Reset stability if send failed maybe?


        # --- Debug Window Update ---
        if DEBUG_WINDOW:
            dbg_frame = frame.copy() # Draw on the BGR frame from camera

            # Draw landmarks if available
            if results.multi_face_landmarks and len(landmarks) > max_needed_idx:
                 for idx in L_EYE + R_EYE + [L_IRIS, R_IRIS, L_TOP, L_BOTTOM, R_TOP, R_BOTTOM]:
                     pt = to_px(landmarks, idx)
                     # Only draw if point is within reasonable bounds (not the default 0,0 from error)
                     if pt[0] != 0 or pt[1] != 0:
                         cv2.circle(dbg_frame, tuple(pt), 2, (0, 255, 0), -1)

            # Draw region indicators
            h = 30
            cv2.rectangle(dbg_frame, (0, CAM_HEIGHT-h), (CAM_WIDTH, CAM_HEIGHT), (50, 50, 50), -1)
            left_px = int(left_threshold * CAM_WIDTH)
            right_px = int(right_threshold * CAM_WIDTH)
            curr_px = int(median_pos[0] * CAM_WIDTH)

            cv2.rectangle(dbg_frame, (0, CAM_HEIGHT-h), (left_px, CAM_HEIGHT), (0, 0, 255), -1) # Left region (Look left = RED)
            cv2.rectangle(dbg_frame, (left_px, CAM_HEIGHT-h), (right_px, CAM_HEIGHT), (0, 255, 0), -1) # Center (GREEN)
            cv2.rectangle(dbg_frame, (right_px, CAM_HEIGHT-h), (CAM_WIDTH, CAM_HEIGHT), (255, 0, 0), -1) # Right region (Look right = BLUE)

            cv2.circle(dbg_frame, (curr_px, CAM_HEIGHT-h//2), 5, (255, 255, 255), -1) # Current pos

            # Display info texts
            cv2.putText(dbg_frame, f'DIR: {label} (Stable: {stable_count})', (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
            cv2.putText(dbg_frame, f'X: {median_pos[0]:.3f}', (10, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
            cv2.putText(dbg_frame, f'EAR: {current_ear:.3f}', (10, 65), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)

            # Pause status (based on local tracking of sent commands)
            status_color = (0, 0, 255) if is_receiver_paused else (0, 255, 0)
            status_text = "PAUSED (Receiver)" if is_receiver_paused else "ACTIVE (Receiver)"
            cv2.putText(dbg_frame, f'RMT ST: {status_text}', (10, 85), cv2.FONT_HERSHEY_SIMPLEX, 0.5, status_color, 1)

            # Connection Status
            conn_color = (0, 255, 0) if client_socket else (0, 0, 255)
            conn_text = "Connected" if client_socket else "DISCONNECTED"
            cv2.putText(dbg_frame, f'NET: {conn_text}', (10, 105), cv2.FONT_HERSHEY_SIMPLEX, 0.5, conn_color, 1)

            # Long blink progress
            if eye_close_start_time > 0:
                close_duration = now - eye_close_start_time
                progress = min(close_duration / LONG_BLINK_DURATION, 1.0) * 100
                cv2.putText(dbg_frame, f'Long Blink: {progress:.0f}%', (10, 125), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)

            # FPS
            fps = 1.0 / (now - prev_frame_time + 1e-6)
            prev_frame_time = now
            cv2.putText(dbg_frame, f'FPS: {fps:.1f}', (CAM_WIDTH - 80, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)

            # Region labels
            cv2.putText(dbg_frame, "LEFT", (left_px//2 - 20, CAM_HEIGHT-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            cv2.putText(dbg_frame, "CENTER", ((left_px+right_px)//2 - 30, CAM_HEIGHT-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            cv2.putText(dbg_frame, "RIGHT", ((right_px+CAM_WIDTH)//2 - 25, CAM_HEIGHT-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

            cv2.imshow('Eye Tracking Sender (Pi)', dbg_frame)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                 print(" 'q' pressed, exiting.")
                 break

        # --- Frame Rate Limiting ---
        # (Keep original FPS limiting logic if needed, though processing might be the bottleneck)
        elapsed = time.time() - now # Time spent in this iteration
        sleep_time = (1.0 / FPS_LIMIT) - elapsed if FPS_LIMIT > 0 else 0
        if sleep_time > 0:
            time.sleep(sleep_time)


except KeyboardInterrupt:
    print("\nProgram interrupted by user (Ctrl+C)")
except Exception as e:
    print(f"\nFATAL Error in main loop: {e}")
finally:
    # --- Cleanup ---
    print("Closing resources...")
    if client_socket:
        try:
            print("Closing network connection.")
            client_socket.close()
        except Exception as e:
            print(f"Error closing socket: {e}")
    if 'cam' in locals() and cam is not None and cam.isOpened():
        print("Releasing camera.")
        cam.release()
    if DEBUG_WINDOW:
        print("Destroying OpenCV windows.")
        cv2.destroyAllWindows()
        # Add a small delay to ensure window closes on some systems
        if platform.system() == "Linux": time.sleep(0.1)

    print("‚ÑπÔ∏è Eye tracking sender stopped.")
